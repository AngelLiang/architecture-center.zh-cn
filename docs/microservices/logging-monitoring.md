---
title: 微服务中的日志记录和监视
description: 微服务中的日志记录和监视
author: MikeWasson
ms.date: 10/23/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: microservices
ms.openlocfilehash: d8263306db4f4c93157ac1d120094338570b4b86
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/23/2019
ms.locfileid: "54482198"
---
# <a name="designing-microservices-logging-and-monitoring"></a><span data-ttu-id="59d69-103">设计微服务：日志记录和监视</span><span class="sxs-lookup"><span data-stu-id="59d69-103">Designing microservices: Logging and monitoring</span></span>

<span data-ttu-id="59d69-104">任何复杂的应用程序偶尔都会出现错误。</span><span class="sxs-lookup"><span data-stu-id="59d69-104">In any complex application, at some point something will go wrong.</span></span> <span data-ttu-id="59d69-105">在微服务应用程序中，需要跟踪几十甚至几百个服务发生的情况。</span><span class="sxs-lookup"><span data-stu-id="59d69-105">In a microservices application, you need to track what's happening across dozens or even hundreds of services.</span></span> <span data-ttu-id="59d69-106">要获取系统的整体视图，日志记录和监视至关重要。</span><span class="sxs-lookup"><span data-stu-id="59d69-106">Logging and monitoring are critically important to give you a holistic view of the system.</span></span>

![微服务体系结构中的监视图](./images/monitoring.png)

<span data-ttu-id="59d69-108">在微服务体系结构中，查明错误或性能瓶颈的确切原因可能特别困难。</span><span class="sxs-lookup"><span data-stu-id="59d69-108">In a microservices architecture, it can be especially challenging to pinpoint the exact cause of errors or performance bottlenecks.</span></span> <span data-ttu-id="59d69-109">单个用户操作可能跨越多个服务。</span><span class="sxs-lookup"><span data-stu-id="59d69-109">A single user operation might span multiple services.</span></span> <span data-ttu-id="59d69-110">服务可能达到群集中的网络 I/O 限制。</span><span class="sxs-lookup"><span data-stu-id="59d69-110">Services may hit network I/O limits inside the cluster.</span></span> <span data-ttu-id="59d69-111">服务之间的调用链可能会在系统中造成反压，从而导致高延迟或连锁故障。</span><span class="sxs-lookup"><span data-stu-id="59d69-111">A chain of calls across services may cause backpressure in the system, resulting in high latency or cascading failures.</span></span> <span data-ttu-id="59d69-112">此外，我们通常不知道特定容器在哪个节点中运行。</span><span class="sxs-lookup"><span data-stu-id="59d69-112">Moreover, you generally don't know which node a particular container will run in.</span></span> <span data-ttu-id="59d69-113">放在同一节点上的容器可能争用有限的 CPU 或内存。</span><span class="sxs-lookup"><span data-stu-id="59d69-113">Containers placed on the same node may be competing for limited CPU or memory.</span></span>

<span data-ttu-id="59d69-114">若要了解所发生的情况，必须通过应用程序收集遥测数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-114">To make sense of what's happening, you must collect telemetry from the application.</span></span>  <span data-ttu-id="59d69-115">可以将遥测数据分为日志和指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-115">Telemetry can be divided into *logs* and *metrics*.</span></span> <span data-ttu-id="59d69-116">[Azure Monitor](/azure/monitoring-and-diagnostics/monitoring-overview) 收集整个 Azure 平台的日志和指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-116">[Azure Monitor](/azure/monitoring-and-diagnostics/monitoring-overview) collects both logs and metrics across the Azure platform.</span></span>

<span data-ttu-id="59d69-117">**日志**是运行应用程序时发生的事件的文本形式记录。</span><span class="sxs-lookup"><span data-stu-id="59d69-117">**Logs** are text-based records of events that occur while the application is running.</span></span> <span data-ttu-id="59d69-118">日志包括应用程序日志（跟踪语句）或 Web 服务器日志等。</span><span class="sxs-lookup"><span data-stu-id="59d69-118">They include things like application logs (trace statements) or web server logs.</span></span> <span data-ttu-id="59d69-119">日志主要用于取证和根本原因分析。</span><span class="sxs-lookup"><span data-stu-id="59d69-119">Logs are primarily useful for forensics and root cause analysis.</span></span>

<span data-ttu-id="59d69-120">指标是可以分析的数字值。</span><span class="sxs-lookup"><span data-stu-id="59d69-120">**Metrics** are numerical values that can be analyzed.</span></span> <span data-ttu-id="59d69-121">可以使用指标实时（或接近实时）观察系统，或者分析不同时间段的性能趋势。</span><span class="sxs-lookup"><span data-stu-id="59d69-121">You can use them to observe the system in real time (or close to real time), or to analyze performance trends over time.</span></span> <span data-ttu-id="59d69-122">指标可以进一步分为：</span><span class="sxs-lookup"><span data-stu-id="59d69-122">Metrics can be further subcategorized as follows:</span></span>

- <span data-ttu-id="59d69-123">**节点级**指标，包括 CPU、内存、网络、磁盘和文件系统的使用情况。</span><span class="sxs-lookup"><span data-stu-id="59d69-123">**Node-level** metrics, including CPU, memory, network, disk, and file system usage.</span></span> <span data-ttu-id="59d69-124">借助系统指标可以了解群集中每个节点的资源分配，以及排查异常。</span><span class="sxs-lookup"><span data-stu-id="59d69-124">System metrics help you to understand resource allocation for each node in the cluster, and troubleshoot outliers.</span></span>

- <span data-ttu-id="59d69-125">**容器**指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-125">**Container** metrics.</span></span> <span data-ttu-id="59d69-126">如果服务在容器中运行，则需在容器级别而不仅仅是 VM 级别收集指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-126">If services are run inside containers, you need to collect metrics at the container level, not just at the VM level.</span></span> <span data-ttu-id="59d69-127">可以将 Azure Monitor 设置为监视 Azure Kubernetes 服务 (AKS) 中的容器工作负荷。</span><span class="sxs-lookup"><span data-stu-id="59d69-127">You can set up Azure Monitor to monitor container workloads in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="59d69-128">有关详细信息，请参阅[适用于容器的 Azure Monitor 概述](/azure/monitoring/monitoring-container-insights-overview)。</span><span class="sxs-lookup"><span data-stu-id="59d69-128">For more information, see [Azure Monitor for containers overview](/azure/monitoring/monitoring-container-insights-overview).</span></span> <span data-ttu-id="59d69-129">对于其他容器业务流程协调程序，请使用 [Log Analytics 中的容器监视解决方案](/azure/log-analytics/log-analytics-containers)。</span><span class="sxs-lookup"><span data-stu-id="59d69-129">For other container orchestrators, use the [Container Monitoring solution in Log Analytics](/azure/log-analytics/log-analytics-containers).</span></span>

- <span data-ttu-id="59d69-130">**应用程序**指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-130">**Application** metrics.</span></span> <span data-ttu-id="59d69-131">包括用于了解服务行为的任何指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-131">This includes any metrics that are relevant to understanding the behavior of a service.</span></span> <span data-ttu-id="59d69-132">示例包括排队的入站 HTTP 请求数、请求延迟或消息队列长度。</span><span class="sxs-lookup"><span data-stu-id="59d69-132">Examples include the number of queued inbound HTTP requests, request latency, or message queue length.</span></span> <span data-ttu-id="59d69-133">应用程序还可以创建特定于域的自定义指标，例如每分钟处理的业务事务数。</span><span class="sxs-lookup"><span data-stu-id="59d69-133">Applications can also create custom metrics that are specific to the domain, such as the number of business transactions processed per minute.</span></span> <span data-ttu-id="59d69-134">通过 [Application Insights](/azure/application-insights/app-insights-overview) 来启用应用程序指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-134">Use [Application Insights](/azure/application-insights/app-insights-overview) to enable application metrics.</span></span>

- <span data-ttu-id="59d69-135">**依赖服务**指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-135">**Dependent service** metrics.</span></span> <span data-ttu-id="59d69-136">服务可能会调用外部服务或终结点，例如托管的 PaaS 服务或 SaaS 服务。</span><span class="sxs-lookup"><span data-stu-id="59d69-136">Services may call external services or endpoints, such as managed PaaS services or SaaS services.</span></span> <span data-ttu-id="59d69-137">第三方服务不一定提供任何指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-137">Third-party services may or may not provide any metrics.</span></span> <span data-ttu-id="59d69-138">如果未提供，则必须依赖自己的应用程序指标来跟踪有关延迟和错误率的统计信息。</span><span class="sxs-lookup"><span data-stu-id="59d69-138">If not, you'll have to rely on your own application metrics to track statistics for latency and error rate.</span></span>

## <a name="considerations"></a><span data-ttu-id="59d69-139">注意事项</span><span class="sxs-lookup"><span data-stu-id="59d69-139">Considerations</span></span>

<span data-ttu-id="59d69-140">[监视和诊断](../best-practices/monitoring.md)一文介绍了有关监视应用程序的一般最佳做法。</span><span class="sxs-lookup"><span data-stu-id="59d69-140">The article [Monitoring and diagnostics](../best-practices/monitoring.md) describes general best practices for monitoring an application.</span></span> <span data-ttu-id="59d69-141">下面是在微服务体系结构上下文中需要考虑的一些具体事项。</span><span class="sxs-lookup"><span data-stu-id="59d69-141">Here are some particular things to think about in the context of a microservices architecture.</span></span>

<span data-ttu-id="59d69-142">**配置和管理**。</span><span class="sxs-lookup"><span data-stu-id="59d69-142">**Configuration and management**.</span></span> <span data-ttu-id="59d69-143">是要使用托管服务进行日志记录和监视，还是将日志记录和监视组件作为容器部署在群集中？</span><span class="sxs-lookup"><span data-stu-id="59d69-143">Will you use a managed service for logging and monitoring, or deploy logging and monitoring components as containers inside the cluster?</span></span> <span data-ttu-id="59d69-144">有关这些选项的更多介绍，请参阅下面的[技术选项](#technology-options)部分。</span><span class="sxs-lookup"><span data-stu-id="59d69-144">For more discussion of these options, see the section [Technology Options](#technology-options) below.</span></span>

<span data-ttu-id="59d69-145">**引入速率**。</span><span class="sxs-lookup"><span data-stu-id="59d69-145">**Ingestion rate**.</span></span> <span data-ttu-id="59d69-146">系统能够以多高的吞吐量引入遥测事件？</span><span class="sxs-lookup"><span data-stu-id="59d69-146">What is the throughput at which the system can ingest telemetry events?</span></span> <span data-ttu-id="59d69-147">如果超过该速率，会发生什么情况？</span><span class="sxs-lookup"><span data-stu-id="59d69-147">What happens if that rate is exceeded?</span></span> <span data-ttu-id="59d69-148">例如，系统可能会限制客户端，在这种情况下，遥测数据将会丢失，或者减少数据采样。</span><span class="sxs-lookup"><span data-stu-id="59d69-148">For example, the system may throttle clients, in which case telemetry data is lost, or it may downsample the data.</span></span> <span data-ttu-id="59d69-149">有时，可以通过减少收集的数据量来缓解此问题：</span><span class="sxs-lookup"><span data-stu-id="59d69-149">Sometimes you can mitigate this problem by reducing the amount of data that you collect:</span></span>

- <span data-ttu-id="59d69-150">通过计算平均值和标准偏差等统计信息来聚合指标，然后将该统计数据发送到监视系统。</span><span class="sxs-lookup"><span data-stu-id="59d69-150">Aggregate metrics by calculating statistics, such as average and standard deviation, and send that statistical data to the monitoring system.</span></span>
- <span data-ttu-id="59d69-151">减少数据采样 &mdash; 即，只处理一定百分比的事件。</span><span class="sxs-lookup"><span data-stu-id="59d69-151">Downsample the data &mdash; that is, process only a percentage of the events.</span></span>
- <span data-ttu-id="59d69-152">批处理数据，以减少监视服务的网络调用次数。</span><span class="sxs-lookup"><span data-stu-id="59d69-152">Batch the data to reduce the number of network calls to the monitoring service.</span></span>

<span data-ttu-id="59d69-153">**成本**。</span><span class="sxs-lookup"><span data-stu-id="59d69-153">**Cost**.</span></span> <span data-ttu-id="59d69-154">引入和存储遥测数据可能会产生较高的成本，尤其是引入大量数据时。</span><span class="sxs-lookup"><span data-stu-id="59d69-154">The cost of ingesting and storing telemetry data may be high, especially at high volumes.</span></span> <span data-ttu-id="59d69-155">在某些情况下，这项成本甚至会超过运行应用程序的成本。</span><span class="sxs-lookup"><span data-stu-id="59d69-155">In some cases it could even exceed the cost of running the application.</span></span> <span data-ttu-id="59d69-156">在这种情况下，可能需要根据前面所述，通过聚合、减少采样或批处理数据，来减少遥测量。</span><span class="sxs-lookup"><span data-stu-id="59d69-156">In that case, you may need to reduce the volume of telemetry by aggregating, downsampling, or batching the data, as described above.</span></span>

<span data-ttu-id="59d69-157">**数据保真度**。</span><span class="sxs-lookup"><span data-stu-id="59d69-157">**Data fidelity**.</span></span> <span data-ttu-id="59d69-158">指标的精确度如何？</span><span class="sxs-lookup"><span data-stu-id="59d69-158">How accurate are the metrics?</span></span> <span data-ttu-id="59d69-159">平均值可能隐藏离群值，尤其是在大规模操作的情况下。</span><span class="sxs-lookup"><span data-stu-id="59d69-159">Averages can hide outliers, especially at scale.</span></span> <span data-ttu-id="59d69-160">此外，如果采样率过低，则数据的波动可能不明显。</span><span class="sxs-lookup"><span data-stu-id="59d69-160">Also, if the sampling rate is too low, it can smooth out fluctuations in the data.</span></span> <span data-ttu-id="59d69-161">看上去所有请求具有相同的端到端延迟，但实际上有相当多的请求花费更长的时间。</span><span class="sxs-lookup"><span data-stu-id="59d69-161">It may appear that all requests have about the same end-to-end latency, when in fact a significant fraction of requests are taking much longer.</span></span>

<span data-ttu-id="59d69-162">**延迟**。</span><span class="sxs-lookup"><span data-stu-id="59d69-162">**Latency**.</span></span> <span data-ttu-id="59d69-163">若要实现实时监视和警报，应快速提供遥测数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-163">To enable real-time monitoring and alerts, telemetry data should be available quickly.</span></span> <span data-ttu-id="59d69-164">数据显示在监视仪表板上的“实时性”有多高？</span><span class="sxs-lookup"><span data-stu-id="59d69-164">How "real-time" is the data that appears on the monitoring dashboard?</span></span> <span data-ttu-id="59d69-165">只需几秒钟？</span><span class="sxs-lookup"><span data-stu-id="59d69-165">A few seconds old?</span></span> <span data-ttu-id="59d69-166">还是需要一分钟以上？</span><span class="sxs-lookup"><span data-stu-id="59d69-166">More than a minute?</span></span>

<span data-ttu-id="59d69-167">**存储**。</span><span class="sxs-lookup"><span data-stu-id="59d69-167">**Storage.**</span></span> <span data-ttu-id="59d69-168">在日志方面，最有有效的做法可能是将日志事件写入群集中的临时存储，并配置一个代理，以将日志文件传送到更持久的存储。</span><span class="sxs-lookup"><span data-stu-id="59d69-168">For logs, it may be most efficient to write the log events to ephemeral storage in the cluster, and configure an agent to ship the log files to more persistent storage.</span></span>  <span data-ttu-id="59d69-169">最终应将数据移到长期存储用于追溯分析。</span><span class="sxs-lookup"><span data-stu-id="59d69-169">Data should eventually be moved to long-term storage so that it's available for retrospective analysis.</span></span> <span data-ttu-id="59d69-170">微服务体系结构可能会生成大量的遥测数据，因此，存储该数据的成本是一个重要的考虑因素。</span><span class="sxs-lookup"><span data-stu-id="59d69-170">A microservices architecture can generate a large volume of telemetry data, so the cost of storing that data is an important consideration.</span></span> <span data-ttu-id="59d69-171">此外，应考虑查询数据的方式。</span><span class="sxs-lookup"><span data-stu-id="59d69-171">Also consider how you will query the data.</span></span>

<span data-ttu-id="59d69-172">**仪表板和可视化效果**。</span><span class="sxs-lookup"><span data-stu-id="59d69-172">**Dashboard and visualization.**</span></span> <span data-ttu-id="59d69-173">是否要跨群集和外部服务中的所有服务获取系统的整体视图？</span><span class="sxs-lookup"><span data-stu-id="59d69-173">Do you get a holistic view of the system, across all of the services, both within the cluster and external services?</span></span> <span data-ttu-id="59d69-174">如果要将遥测数据和日志写入多个位置，仪表板是否可以显示并关联所有这些信息？</span><span class="sxs-lookup"><span data-stu-id="59d69-174">If you are writing telemetry data and logs to more than one location, can the dashboard show all of them and correlate?</span></span> <span data-ttu-id="59d69-175">监视仪表板至少应显示以下信息：</span><span class="sxs-lookup"><span data-stu-id="59d69-175">The monitoring dashboard should show at least the following information:</span></span>

- <span data-ttu-id="59d69-176">总体资源分配容量和增长情况。</span><span class="sxs-lookup"><span data-stu-id="59d69-176">Overall resource allocation for capacity and growth.</span></span> <span data-ttu-id="59d69-177">这包括容器数目、文件系统指标、网络和核心分配。</span><span class="sxs-lookup"><span data-stu-id="59d69-177">This includes the number of containers, file system metrics, network, and core allocation.</span></span>
- <span data-ttu-id="59d69-178">在服务级别关联的容器指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-178">Container metrics correlated at the service level.</span></span>
- <span data-ttu-id="59d69-179">与容器关联的系统指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-179">System metrics correlated with containers.</span></span>
- <span data-ttu-id="59d69-180">服务错误和异常。</span><span class="sxs-lookup"><span data-stu-id="59d69-180">Service errors and outliers.</span></span>

## <a name="distributed-tracing"></a><span data-ttu-id="59d69-181">分布式跟踪</span><span class="sxs-lookup"><span data-stu-id="59d69-181">Distributed tracing</span></span>

<span data-ttu-id="59d69-182">如前所述，微服务中的难题之一是如何了解跨服务的事件流。</span><span class="sxs-lookup"><span data-stu-id="59d69-182">As mentioned, one challenge in microservices is understanding the flow of events across services.</span></span> <span data-ttu-id="59d69-183">单个操作或事务可能涉及对多个服务的调用。</span><span class="sxs-lookup"><span data-stu-id="59d69-183">A single operation or transaction may involve calls to multiple services.</span></span> <span data-ttu-id="59d69-184">若要重新构造整个步骤序列，每个服务应该传播一个关联 ID 用于充当该操作的唯一标识符。</span><span class="sxs-lookup"><span data-stu-id="59d69-184">To reconstruct the entire sequence of steps, each service should propagate a *correlation ID* that acts as a unique identifier for that operation.</span></span> <span data-ttu-id="59d69-185">该关联 ID 可以实现跨服务的[分布式跟踪](https://microservices.io/patterns/observability/distributed-tracing.html)。</span><span class="sxs-lookup"><span data-stu-id="59d69-185">The correlation ID enables [distributed tracing](https://microservices.io/patterns/observability/distributed-tracing.html) across services.</span></span>

<span data-ttu-id="59d69-186">接收客户端请求的第一个服务应生成关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-186">The first service that receives a client request should generate the correlation ID.</span></span> <span data-ttu-id="59d69-187">如果该服务对另一服务发出 HTTP 调用，它会在请求标头中放置关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-187">If the service makes an HTTP call to another service, it puts the correlation ID in a request header.</span></span> <span data-ttu-id="59d69-188">同样，如果该服务发送异步消息，则会在该消息中放置关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-188">Similarly, if the service sends an asynchronous message, it puts the correlation ID into the message.</span></span> <span data-ttu-id="59d69-189">下游服务继续传播关联 ID，以便可以流经整个系统。</span><span class="sxs-lookup"><span data-stu-id="59d69-189">Downstream services continue to propagate the correlation ID, so that it flows through the entire system.</span></span> <span data-ttu-id="59d69-190">此外，写入应用程序指标或日志事件的所有代码都应包含关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-190">In addition, all code that writes application metrics or log events should include the correlation ID.</span></span>

<span data-ttu-id="59d69-191">关联服务调用后，可以计算操作指标，例如整个事务的端到端延迟、每秒成功的事务数和失败的事务百分比。</span><span class="sxs-lookup"><span data-stu-id="59d69-191">When service calls are correlated, you can calculate operational metrics such as the end-to-end latency for a complete transaction, the number of successful transactions per second, and the percentage of failed transactions.</span></span> <span data-ttu-id="59d69-192">在应用程序日志中包含关联 ID 可以执行根本原因分析。</span><span class="sxs-lookup"><span data-stu-id="59d69-192">Including correlation IDs in application logs makes it possible to perform root cause analysis.</span></span> <span data-ttu-id="59d69-193">如果某个操作失败，你可以查找同一操作中包含的所有服务调用的日志语句。</span><span class="sxs-lookup"><span data-stu-id="59d69-193">If an operation fails, you can find the log statements for all of the service calls that were part of the same operation.</span></span>

<span data-ttu-id="59d69-194">下面是在实施分布式跟踪时的一些注意事项：</span><span class="sxs-lookup"><span data-stu-id="59d69-194">Here are some considerations when implementing distributed tracing:</span></span>

- <span data-ttu-id="59d69-195">目前，关联 ID 没有标准的 HTTP 标头。</span><span class="sxs-lookup"><span data-stu-id="59d69-195">There is currently no standard HTTP header for correlation IDs.</span></span> <span data-ttu-id="59d69-196">团队应该针对自定义标头值进行标准化。</span><span class="sxs-lookup"><span data-stu-id="59d69-196">Your team should standardize on a custom header value.</span></span> <span data-ttu-id="59d69-197">请根据日志记录/监视框架或所选的服务网格做出选择。</span><span class="sxs-lookup"><span data-stu-id="59d69-197">The choice may be decided by your logging/monitoring framework or choice of service mesh.</span></span>

- <span data-ttu-id="59d69-198">对于异步消息，如果消息传递基础结构支持将元数据添加到消息，则应将关联 ID 包含为元数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-198">For asynchronous messages, if your messaging infrastructure supports adding metadata to messages, you should include the correlation ID as metadata.</span></span> <span data-ttu-id="59d69-199">否则，请将关联 ID 包含为消息架构的一部分。</span><span class="sxs-lookup"><span data-stu-id="59d69-199">Otherwise, include it as part of the message schema.</span></span>

- <span data-ttu-id="59d69-200">如果不包含单个不透明标识符，可以发送一个包含更丰富信息（例如调用方-被调用方关系）的关联上下文。</span><span class="sxs-lookup"><span data-stu-id="59d69-200">Rather than a single opaque identifier, you might send a *correlation context* that includes richer information, such as caller-callee relationships.</span></span>

- <span data-ttu-id="59d69-201">Azure Application Insights SDK 会自动将关联上下文注入 HTTP 标头，并在 Application Insights 日志中包含关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-201">The Azure Application Insights SDK automatically injects correlation context into HTTP headers, and includes the correlation ID in Application Insights logs.</span></span> <span data-ttu-id="59d69-202">如果你确定使用 Application Insights 中内置的关联功能，根据所用的库，某些服务可能仍需要显式传播关联标头。</span><span class="sxs-lookup"><span data-stu-id="59d69-202">If you decide to use the correlation features built into Application Insights, some services may still need to explicitly propagate the correlation headers, depending on the libraries being used.</span></span> <span data-ttu-id="59d69-203">有关详细信息，请参阅 [Application Insights 中的遥测关联](/azure/application-insights/application-insights-correlation)。</span><span class="sxs-lookup"><span data-stu-id="59d69-203">For more information, see [Telemetry correlation in Application Insights](/azure/application-insights/application-insights-correlation).</span></span>

- <span data-ttu-id="59d69-204">如果使用 Istio 或 linkerd 作为服务网格，当通过服务网格代理路由 HTTP 调用时，这些技术会自动生成关联标头。</span><span class="sxs-lookup"><span data-stu-id="59d69-204">If you are using Istio or linkerd as a service mesh, these technologies automatically generate correlation headers when HTTP calls are routed through the service mesh proxies.</span></span> <span data-ttu-id="59d69-205">服务应转发关联标头。</span><span class="sxs-lookup"><span data-stu-id="59d69-205">Services should forward the relevant headers.</span></span>

  - <span data-ttu-id="59d69-206">Istio：[分布式请求跟踪](https://istio-releases.github.io/v0.1/docs/tasks/zipkin-tracing.html)</span><span class="sxs-lookup"><span data-stu-id="59d69-206">Istio: [Distributed Request Tracing](https://istio-releases.github.io/v0.1/docs/tasks/zipkin-tracing.html)</span></span>
  - <span data-ttu-id="59d69-207">linkerd：[上下文标头](https://linkerd.io/config/1.3.0/linkerd/index.html#http-headers)</span><span class="sxs-lookup"><span data-stu-id="59d69-207">linkerd: [Context Headers](https://linkerd.io/config/1.3.0/linkerd/index.html#http-headers)</span></span>

- <span data-ttu-id="59d69-208">请考虑如何聚合日志。</span><span class="sxs-lookup"><span data-stu-id="59d69-208">Consider how you will aggregate logs.</span></span> <span data-ttu-id="59d69-209">可能需要在不同的团队之间标准化在日志中包含关联 ID 的方式。</span><span class="sxs-lookup"><span data-stu-id="59d69-209">You may want to standardize across teams on how to include correlation IDs in logs.</span></span> <span data-ttu-id="59d69-210">使用结构化或半结构化格式（例如 JSON），并定义一个公用字段来保存关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-210">Use a structured or semi-structured format, such as JSON, and define a common field to hold the correlation ID.</span></span>

## <a name="technology-options"></a><span data-ttu-id="59d69-211">技术选项</span><span class="sxs-lookup"><span data-stu-id="59d69-211">Technology options</span></span>

<span data-ttu-id="59d69-212">**Application Insights** 是 Azure 中的一个托管服务，可引入和存储遥测数据，并提供用于分析和搜索数据的工具。</span><span class="sxs-lookup"><span data-stu-id="59d69-212">**Application Insights** is a managed service in Azure that ingests and stores telemetry data, and provides tools for analyzing and searching the data.</span></span> <span data-ttu-id="59d69-213">若要使用 Application Insights，请在应用程序中安装一个检测包。</span><span class="sxs-lookup"><span data-stu-id="59d69-213">To use Application Insights, you install an instrumentation package in your application.</span></span> <span data-ttu-id="59d69-214">此包可监视应用，并将遥测数据发送到 Application Insights 服务。</span><span class="sxs-lookup"><span data-stu-id="59d69-214">This package monitors the app and sends telemetry data to the Application Insights service.</span></span> <span data-ttu-id="59d69-215">此外，它还可以从宿主环境提取遥测数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-215">It can also pull telemetry data from the host environment.</span></span> <span data-ttu-id="59d69-216">Application Insights 提供内置的关联和依赖项跟踪。</span><span class="sxs-lookup"><span data-stu-id="59d69-216">Application Insights provides built-in correlation and dependency tracking.</span></span> <span data-ttu-id="59d69-217">可以在 Application Insights 中的单个位置跟踪系统指标、应用程序指标和 Azure 服务指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-217">It lets you track system metrics, application metrics, and Azure service metrics, all in one place.</span></span>

<span data-ttu-id="59d69-218">请注意，如果数据传输率超过最大限制，则 Application Insights 会实施限制；有关详细信息，请参阅 [Application Insights 限制](/azure/azure-subscription-service-limits#application-insights-limits)。</span><span class="sxs-lookup"><span data-stu-id="59d69-218">Be aware that Application Insights throttles if the data rate exceeds a maximum limit; for details, see [Application Insights limits](/azure/azure-subscription-service-limits#application-insights-limits).</span></span> <span data-ttu-id="59d69-219">单个操作可能生成多个遥测事件，因此，如果应用程序遇到较大的流量，可能会受到限制。</span><span class="sxs-lookup"><span data-stu-id="59d69-219">A single operation may generate several telemetry events, so if the application experiences a high volume of traffic, it is likely to get throttled.</span></span> <span data-ttu-id="59d69-220">若要缓解此问题，可以执行采样来减少遥测流量。</span><span class="sxs-lookup"><span data-stu-id="59d69-220">To mitigate this problem, you can perform sampling to reduce the telemetry traffic.</span></span> <span data-ttu-id="59d69-221">弊端是指标的精确度会下降。</span><span class="sxs-lookup"><span data-stu-id="59d69-221">The tradeoff is that your metrics will be less precise.</span></span> <span data-ttu-id="59d69-222">有关详细信息，请参阅 [Application Insights 中的采样](/azure/application-insights/app-insights-sampling)。</span><span class="sxs-lookup"><span data-stu-id="59d69-222">For more information, see [Sampling in Application Insights](/azure/application-insights/app-insights-sampling).</span></span> <span data-ttu-id="59d69-223">也可以通过预先聚合指标来减少数据量 &mdash; 即，计算平均值和标准偏差等统计值，然后发送这些值而不是原始遥测数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-223">You can also reduce the data volume by pre-aggregating metrics &mdash; that is, calculating statistical values such as average and standard deviation, and sending those values instead of the raw telemetry.</span></span> <span data-ttu-id="59d69-224">以下博客文章介绍了大规模使用 Application Insights 的方法：[Azure Monitoring and Analytics at Scale](https://blogs.msdn.microsoft.com/azurecat/2017/05/11/azure-monitoring-and-analytics-at-scale/)（大规模使用 Azure 监视和分析）。</span><span class="sxs-lookup"><span data-stu-id="59d69-224">The following blog post describes an approach to using Application Insights at scale: [Azure Monitoring and Analytics at Scale](https://blogs.msdn.microsoft.com/azurecat/2017/05/11/azure-monitoring-and-analytics-at-scale/).</span></span>

<span data-ttu-id="59d69-225">此外，请确保了解 Application Insights 的定价模型，因为该产品根据数据量收费。</span><span class="sxs-lookup"><span data-stu-id="59d69-225">In addition, make sure that you understand the pricing model for Application Insights, because you are charged based on data volume.</span></span> <span data-ttu-id="59d69-226">有关详细信息，请参阅[在 Application Insights 中管理定价和数据量](/azure/application-insights/app-insights-pricing)。</span><span class="sxs-lookup"><span data-stu-id="59d69-226">For more information, see [Manage pricing and data volume in Application Insights](/azure/application-insights/app-insights-pricing).</span></span> <span data-ttu-id="59d69-227">如果应用程序生成大量遥测数据，而你不希望对这些数据执行采样或聚合，则 Application Insights 可能不是适当的选择。</span><span class="sxs-lookup"><span data-stu-id="59d69-227">If your application generates a large volume of telemetry, and you don't wish to perform sampling or aggregation of the data, then Application Insights may not be the appropriate choice.</span></span>

<span data-ttu-id="59d69-228">如果 Application Insights 不满足要求，可以参考以下一些建议的方法来使用流行开源技术。</span><span class="sxs-lookup"><span data-stu-id="59d69-228">If Application Insights doesn't meet your requirements, here are some suggested approaches that use popular open-source technologies.</span></span>

<span data-ttu-id="59d69-229">对于系统和容器指标，请考虑将指标导出到群集中运行的时序数据库，例如 **Prometheus** 或 **InfluxDB**。</span><span class="sxs-lookup"><span data-stu-id="59d69-229">For system and container metrics, consider exporting metrics to a time-series database such as **Prometheus** or **InfluxDB** running in the cluster.</span></span>

- <span data-ttu-id="59d69-230">InfluxDB 是基于推送的系统。</span><span class="sxs-lookup"><span data-stu-id="59d69-230">InfluxDB is a push-based system.</span></span> <span data-ttu-id="59d69-231">某个代理需要推送指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-231">An agent needs to push the metrics.</span></span> <span data-ttu-id="59d69-232">在这种情况下，可以使用 [Heapster][heapster]，该服务可从 kubelet 收集整个群集的指标，聚合数据，然后将其推送到 InfluxDB 或其他时序存储解决方案。</span><span class="sxs-lookup"><span data-stu-id="59d69-232">You can use [Heapster][heapster], which is a service that collects cluster-wide metrics from kubelet, aggregates the data, and pushes it to InfluxDB or other time-series storage solution.</span></span> <span data-ttu-id="59d69-233">在设置群集的过程中，Azure 容器服务会部署 Heapster。</span><span class="sxs-lookup"><span data-stu-id="59d69-233">Azure Container Service deploys Heapster as part of the cluster setup.</span></span> <span data-ttu-id="59d69-234">另一个选项是 [Telegraf](https://www.influxdata.com/time-series-platform/telegraf/)，这是一个用于收集和报告指标的代理。</span><span class="sxs-lookup"><span data-stu-id="59d69-234">Another option is [Telegraf](https://www.influxdata.com/time-series-platform/telegraf/), which is an agent for collecting and reporting metrics.</span></span>

- <span data-ttu-id="59d69-235">Prometheus 是基于提取的系统。</span><span class="sxs-lookup"><span data-stu-id="59d69-235">Prometheus is a pull-based system.</span></span> <span data-ttu-id="59d69-236">它定期从配置的位置擦除指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-236">It periodically scrapes metrics from configured locations.</span></span> <span data-ttu-id="59d69-237">Prometheus 可以擦除 cAdvisor 或 kube-state-metrics 生成的指标。</span><span class="sxs-lookup"><span data-stu-id="59d69-237">Prometheus can scrape metrics generated by cAdvisor or kube-state-metrics.</span></span> <span data-ttu-id="59d69-238">[kube-state-metrics][kube-state-metrics] 服务从 Kubernetes API 服务器收集指标，然后将这些指标提供给 Prometheus（或者与 Prometheus 客户端终结点兼容的擦除程序）。</span><span class="sxs-lookup"><span data-stu-id="59d69-238">[kube-state-metrics][kube-state-metrics] is a service that collects metrics from the Kubernetes API server and makes them available to Prometheus (or a scraper that is compatible with a Prometheus client endpoint).</span></span> <span data-ttu-id="59d69-239">Heapster 聚合 Kubernetes 生成的指标并将其转发到接收器，而 kube-state-metrics 生成自身的指标并通过终结点提供这些指标以进行擦除。</span><span class="sxs-lookup"><span data-stu-id="59d69-239">Whereas Heapster aggregates metrics that Kubernetes generates and forwards them to a sink, kube-state-metrics generates its own metrics and makes them available through an endpoint for scraping.</span></span> <span data-ttu-id="59d69-240">对于系统指标，请使用 [Node 导出程序](https://github.com/prometheus/node_exporter)，这是一个针对系统指标的 Prometheus 导出程序。</span><span class="sxs-lookup"><span data-stu-id="59d69-240">For system metrics, use [Node exporter](https://github.com/prometheus/node_exporter), which is a Prometheus exporter for system metrics.</span></span> <span data-ttu-id="59d69-241">Prometheus 支持浮点数据，但不支持字符串数据，因此，它适合用于系统指标，而不适合用于日志。</span><span class="sxs-lookup"><span data-stu-id="59d69-241">Prometheus supports floating point data, but not string data, so it is appropriate for system metrics but not logs.</span></span>

- <span data-ttu-id="59d69-242">使用 **Kibana** 或 **Grafana** 等仪表板工具来可视化和监视数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-242">Use a dashboard tool such as **Kibana** or **Grafana** to visualize and monitor the data.</span></span> <span data-ttu-id="59d69-243">仪表板服务还可以在群集中的容器内运行。</span><span class="sxs-lookup"><span data-stu-id="59d69-243">The dashboard service can also run inside a container in the cluster.</span></span>

<span data-ttu-id="59d69-244">对于应用程序日志，请考虑使用 **Fluentd** 和 **Elasticsearch**。</span><span class="sxs-lookup"><span data-stu-id="59d69-244">For application logs, consider using **Fluentd** and **Elasticsearch**.</span></span> <span data-ttu-id="59d69-245">Fluentd 是一个开源数据收集器，Elasticsearch 是经过优化的文档数据库，可以充当搜索引擎。</span><span class="sxs-lookup"><span data-stu-id="59d69-245">Fluentd is an open source data collector, and Elasticsearch is a document database that is optimized to act as a search engine.</span></span> <span data-ttu-id="59d69-246">使用此方法，每个服务可将日志发送到 `stdout` 和 `stderr`，而 Kubernetes 可将这些流写入本地文件系统。</span><span class="sxs-lookup"><span data-stu-id="59d69-246">Using this approach, each service sends logs to `stdout` and `stderr`, and Kubernetes writes these streams to the local file system.</span></span> <span data-ttu-id="59d69-247">Fluentd 收集日志，并选择性地使用来自 Kubernetes 的其他元数据丰富这些日志，然后将日志发送到 Elasticsearch。</span><span class="sxs-lookup"><span data-stu-id="59d69-247">Fluentd collects the logs, optionally enriches them with additional metadata from Kubernetes, and sends the logs to Elasticsearch.</span></span> <span data-ttu-id="59d69-248">使用 Kibana、Grafana 或类似工具为 Elasticsearch 创建仪表板。</span><span class="sxs-lookup"><span data-stu-id="59d69-248">Use Kibana, Grafana, or a similar tool to create a dashboard for Elasticsearch.</span></span> <span data-ttu-id="59d69-249">Fluentd 在群集中作为守护程序集运行，确保为每个节点分配一个 Fluentd pod。</span><span class="sxs-lookup"><span data-stu-id="59d69-249">Fluentd runs as a daemonset in the cluster, which ensures that one Fluentd pod is assigned to each node.</span></span> <span data-ttu-id="59d69-250">可将 Fluentd 配置为收集 kubelet 日志和容器日志。</span><span class="sxs-lookup"><span data-stu-id="59d69-250">You can configure Fluentd to collect kubelet logs as well as container logs.</span></span> <span data-ttu-id="59d69-251">在数据量较高的情况下，将日志写入本地文件系统可能造成性能瓶颈，尤其是多个服务在同一个节点上运行时。</span><span class="sxs-lookup"><span data-stu-id="59d69-251">At high volumes, writing logs to the local file system could become a performance bottleneck, especially when multiple services are running on the same node.</span></span> <span data-ttu-id="59d69-252">监视生产环境中的磁盘延迟和文件系统利用率。</span><span class="sxs-lookup"><span data-stu-id="59d69-252">Monitor disk latency and file system utilization in production.</span></span>

<span data-ttu-id="59d69-253">为日志结合使用 Fluentd 和 Elasticsearch 的优势之一是，服务不需要任何附加的库依赖项。</span><span class="sxs-lookup"><span data-stu-id="59d69-253">One advantage of using Fluentd with Elasticsearch for logs is that services do not require any additional library dependencies.</span></span> <span data-ttu-id="59d69-254">每个服务只需写入 `stdout` 和 `stderr`，而 Fluentd 会处理将日志导出到 Elasticsearch 的过程。</span><span class="sxs-lookup"><span data-stu-id="59d69-254">Each service just writes to `stdout` and `stderr`, and Fluentd handles exporting the logs into Elasticsearch.</span></span> <span data-ttu-id="59d69-255">此外，编写服务的团队无需了解如何配置日志记录基础结构。</span><span class="sxs-lookup"><span data-stu-id="59d69-255">Also, the teams writing services don't need to understand how to configure the logging infrastructure.</span></span> <span data-ttu-id="59d69-256">难题之一是如何为生产部署配置 Elasticsearch 群集，使其能够根据流量处理要求进行缩放。</span><span class="sxs-lookup"><span data-stu-id="59d69-256">One challenge is to configure the Elasticsearch cluster for a production deployment, so that it scales to handle your traffic.</span></span>

<span data-ttu-id="59d69-257">另一种做法是将日志发送到 Operations Management Suite (OMS) Log Analytics。</span><span class="sxs-lookup"><span data-stu-id="59d69-257">Another option is to send logs to Operations Management Suite (OMS) Log Analytics.</span></span> <span data-ttu-id="59d69-258">[Log Analytics][log-analytics] 服务将日志数据收集到中心存储库，此外还可以合并来自应用程序使用的其他 Azure 服务的数据。</span><span class="sxs-lookup"><span data-stu-id="59d69-258">The [Log Analytics][log-analytics] service collects log data into a central repository, and can also consolidate data from other Azure services that your application uses.</span></span> <span data-ttu-id="59d69-259">有关详细信息，请参阅[使用 Microsoft Operations Management Suite (OMS) 监视 Azure 容器服务群集][k8s-to-oms]。</span><span class="sxs-lookup"><span data-stu-id="59d69-259">For more information, see [Monitor an Azure Container Service cluster with Microsoft Operations Management Suite (OMS)][k8s-to-oms].</span></span>

## <a name="example-logging-with-correlation-ids"></a><span data-ttu-id="59d69-260">示例：使用关联 ID 的日志记录</span><span class="sxs-lookup"><span data-stu-id="59d69-260">Example: Logging with correlation IDs</span></span>

<span data-ttu-id="59d69-261">为了演示本章所述的某些要点，下面提供了一个有关 Package 服务如何实现日志记录的详细示例。</span><span class="sxs-lookup"><span data-stu-id="59d69-261">To illustrate some of the points discussed in this chapter, here is an extended example of how the Package service implements logging.</span></span> <span data-ttu-id="59d69-262">该 Package 服务是以 TypeScript 编写的，使用适用于 Node.js 的 [Koa](https://koajs.com/) Web 框架。</span><span class="sxs-lookup"><span data-stu-id="59d69-262">The Package service was written in TypeScript and uses the [Koa](https://koajs.com/) web framework for Node.js.</span></span> <span data-ttu-id="59d69-263">可以在多个 Node.js 日志记录库中进行选择。</span><span class="sxs-lookup"><span data-stu-id="59d69-263">There are several Node.js logging libraries to choose from.</span></span> <span data-ttu-id="59d69-264">我们选择了 [Winston](https://github.com/winstonjs/winston)，经过测试，它是符合我们性能要求的流行日志记录库。</span><span class="sxs-lookup"><span data-stu-id="59d69-264">We picked [Winston](https://github.com/winstonjs/winston), a popular logging library that met our performance requirements when we tested it.</span></span>

<span data-ttu-id="59d69-265">为了封装实现详细信息，我们定义了一个抽象 `ILogger` 接口：</span><span class="sxs-lookup"><span data-stu-id="59d69-265">To encapsulate the implementation details, we defined an abstract  `ILogger` interface:</span></span>

```ts
export interface ILogger {
    log(level: string, msg: string, meta?: any)
    debug(msg: string, meta?: any)
    info(msg: string, meta?: any)
    warn(msg: string, meta?: any)
    error(msg: string, meta?: any)
}
```

<span data-ttu-id="59d69-266">下面是包装 Winston 库的 `ILogger` 实现。</span><span class="sxs-lookup"><span data-stu-id="59d69-266">Here is an `ILogger` implementation that wraps the Winston library.</span></span> <span data-ttu-id="59d69-267">该实例使用关联 ID 作为构造函数参数，并将该 ID 注入每个日志消息。</span><span class="sxs-lookup"><span data-stu-id="59d69-267">It takes the correlation ID as a constructor parameter, and injects the ID into every log message.</span></span>

```ts
class WinstonLogger implements ILogger {
    constructor(private correlationId: string) {}
    log(level: string, msg: string, payload?: any) {
        var meta : any = {};
        if (payload) { meta.payload = payload };
        if (this.correlationId) { meta.correlationId = this.correlationId }
        winston.log(level, msg, meta)
    }
  
    info(msg: string, payload?: any) {
        this.log('info', msg, payload);
    }
    debug(msg: string, payload?: any) {
        this.log('debug', msg, payload);
    }
    warn(msg: string, payload?: any) {
        this.log('warn', msg, payload);
    }
    error(msg: string, payload?: any) {
        this.log('error', msg, payload);
    }
}
```

<span data-ttu-id="59d69-268">Package 服务需要从 HTTP 请求提取关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-268">The Package service needs to extract the correlation ID from the HTTP request.</span></span> <span data-ttu-id="59d69-269">例如，如果使用的是 linkerd，则可以在 `l5d-ctx-trace` 标头中找到关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-269">For example, if you're using linkerd, the correlation ID is found in the `l5d-ctx-trace` header.</span></span> <span data-ttu-id="59d69-270">在 Koa 中，HTTP 请求存储在通过请求处理管道传递的 Context 对象中。</span><span class="sxs-lookup"><span data-stu-id="59d69-270">In Koa, the HTTP request is stored in a Context object that gets passed through the request processing pipeline.</span></span> <span data-ttu-id="59d69-271">我们可以定义一个中间件函数，以便从 Context 获取关联 ID 并初始化记录器。</span><span class="sxs-lookup"><span data-stu-id="59d69-271">We can define a middleware function to get the correlation ID from the Context and initialize the logger.</span></span> <span data-ttu-id="59d69-272">（Koa 中的中间件函数只是一个针对每个请求执行的函数。）</span><span class="sxs-lookup"><span data-stu-id="59d69-272">(A middleware function in Koa is simply a function that gets executed for each request.)</span></span>

```ts
export type CorrelationIdFn = (ctx: Context) => string;

export function logger(level: string, getCorrelationId: CorrelationIdFn) {
    winston.configure({
        level: level,
        transports: [new (winston.transports.Console)()]
        });
    return async function(ctx: any, next: any) {
        ctx.state.logger = new WinstonLogger(getCorrelationId(ctx));
        await next();
    }
}
```

<span data-ttu-id="59d69-273">此中间件调用调用方定义的函数 `getCorrelationId`，以获取关联 ID。</span><span class="sxs-lookup"><span data-stu-id="59d69-273">This middleware invokes a caller-defined function, `getCorrelationId`, to get the correlation ID.</span></span> <span data-ttu-id="59d69-274">然后，它创建记录器的实例并将其储藏在 `ctx.state`（Koa 中使用的一个键值字典，用于通过管道传递信息）中。</span><span class="sxs-lookup"><span data-stu-id="59d69-274">Then it creates an instance of the logger and stashes it inside `ctx.state`, which is a key-value dictionary used in Koa to pass information through the pipeline.</span></span>

<span data-ttu-id="59d69-275">在启动时，记录器中间件将添加到管道：</span><span class="sxs-lookup"><span data-stu-id="59d69-275">The logger middleware is added to the pipeline on startup:</span></span>

```ts
app.use(logger(Settings.logLevel(), function (ctx) {
    return ctx.headers[Settings.correlationHeader()];  
}));
```

<span data-ttu-id="59d69-276">完成所有配置后，便可以轻松地将日志记录语句添加到代码中。</span><span class="sxs-lookup"><span data-stu-id="59d69-276">Once everything is configured, it's easy to add logging statements to the code.</span></span> <span data-ttu-id="59d69-277">例如，下面是一个查找包的方法。</span><span class="sxs-lookup"><span data-stu-id="59d69-277">For example, here is the method that looks up a package.</span></span> <span data-ttu-id="59d69-278">该方法对 `ILogger.info` 方法发出两次调用。</span><span class="sxs-lookup"><span data-stu-id="59d69-278">It makes two calls to the `ILogger.info` method.</span></span>

```ts
async getById(ctx: any, next: any) {
  var logger : ILogger = ctx.state.logger;
  var packageId = ctx.params.packageId;
  logger.info('Entering getById, packageId = %s', packageId);

  await next();

  let pkg = await this.repository.findPackage(ctx.params.packageId)

  if (pkg == null) {
    logger.info(`getById: %s not found`, packageId);
    ctx.response.status= 404;
    return;
  }

  ctx.response.status = 200;
  ctx.response.body = this.mapPackageDbToApi(pkg);
}
```

<span data-ttu-id="59d69-279">我们不需要在日志记录语句中包含关联 ID，因为中间件函数会自动执行该操作。</span><span class="sxs-lookup"><span data-stu-id="59d69-279">We don't need to include the correlation ID in the logging statements, because that's done automatically by the middleware function.</span></span> <span data-ttu-id="59d69-280">这可以使日志记录代码显得更简洁，并可以减少开发人员忘记包含关联 ID 的可能性。</span><span class="sxs-lookup"><span data-stu-id="59d69-280">This makes the logging code cleaner, and reduces the chance that a developer will forget to include the correlation ID.</span></span> <span data-ttu-id="59d69-281">此外，由于所有日志记录语句使用抽象 `ILogger` 接口，因此以后我们可以轻松替换记录器实现。</span><span class="sxs-lookup"><span data-stu-id="59d69-281">And because all of the logging statements use the abstract `ILogger` interface, it would be easy to replace the logger implementation later.</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="59d69-282">持续集成和交付</span><span class="sxs-lookup"><span data-stu-id="59d69-282">Continuous integration and delivery</span></span>](./ci-cd.md)

<!-- links -->

[app-insights]: /azure/application-insights/app-insights-overview
[heapster]: https://github.com/kubernetes/heapster
[kube-state-metrics]: https://github.com/kubernetes/kube-state-metrics
[k8s-to-oms]: /azure/container-service/kubernetes/container-service-kubernetes-oms
[log-analytics]: /azure/log-analytics/
